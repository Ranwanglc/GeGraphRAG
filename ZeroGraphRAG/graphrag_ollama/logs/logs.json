{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n    yield\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 394, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 256, in handle_async_request\n    raise exc from None\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 236, in handle_async_request\n    response = await connection.handle_async_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 103, in handle_async_request\n    return await self._connection.handle_async_request(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 136, in handle_async_request\n    raise exc\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 106, in handle_async_request\n    ) = await self._receive_response_headers(**kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 177, in _receive_response_headers\n    event = await self._receive_event(timeout=timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 217, in _receive_event\n    data = await self._network_stream.read(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 32, in read\n    with map_exceptions(exc_map):\n  File \"D:\\app\\AnaConda\\Lib\\contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    response = await self._client.send(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_client.py\", line 1629, in send\n    response = await self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_client.py\", line 1657, in _send_handling_auth\n    response = await self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_client.py\", line 1694, in _send_handling_redirects\n    response = await self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_client.py\", line 1730, in _send_single_request\n    response = await transport.handle_async_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 393, in handle_async_request\n    with map_httpcore_exceptions():\n  File \"D:\\app\\AnaConda\\Lib\\contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 137, in invoke\n    result = await delegate(prompt, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\rate_limiter.py\", line 75, in invoke\n    result = await delegate(prompt, **args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 126, in _decorator_target\n    output = await self._execute_llm(prompt, kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_text_chat_llm.py\", line 166, in _execute_llm\n    raw_response = await self._client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\_legacy_response.py\", line 381, in wrapped\n    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2454, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\_base_client.py\", line 1784, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    raise APITimeoutError(request=request) from err\nopenai.APITimeoutError: Request timed out.\n",
    "source": "Request timed out.",
    "details": {
        "prompt": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n",
        "kwargs": {
            "history": [
                {
                    "content": "\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity's attributes and activities\nFormat each entity as (\"entity\"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as (\"relationship\"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis's Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n(\"entity\"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n(\"entity\"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n(\"entity\"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis's money supply)\n##\n(\"relationship\"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal's (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation's debut on the public markets isn't indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n(\"entity\"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n(\"entity\"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n(\"relationship\"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad's capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia's capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia's Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n(\"entity\"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n(\"entity\"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n(\"entity\"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n(\"entity\"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n(\"entity\"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n(\"entity\"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n(\"entity\"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia's Alhamia Prison)\n##\n(\"entity\"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n(\"entity\"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n(\"entity\"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n(\"relationship\"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n(\"relationship\"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n(\"relationship\"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n(\"relationship\"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n(\"relationship\"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n(\"relationship\"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n(\"relationship\"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n(\"relationship\"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n(\"relationship\"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n(\"relationship\"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 而是轻蔑地对凡卡说：“穷小子，撞死活该！写封信——不贴邮票，不写收信人地址，谁给你寄！”\n\n说完，便用手一撕，再一撕，再撕，再撕……手一扬，风一吹，凡卡给爷爷写的信\n######################\nOutput:",
                    "role": "user"
                },
                {
                    "role": "assistant",
                    "content": "## Identified Entities and Relationships\n\n### Entities:\n\n1. **凡卡 (Vanilla Cake)** - (\"entity\"<|>凡卡<|>PERSON<|>Vanilla Cake is a person who wrote a letter to his grandfather)\n2. **穷小子 (Poor Little Boy)** - (\"entity\"<|>穷小子<|>ORGANIZATION<|>Poor Little Boy is an organization that was written about in the text)\n3. **撞死活该 (Doomed to Live) - (\"entity\"<|>撞死活该<|>EVENT<|>Doomed to live is an event mentioned in the text)\n4. **写封信 (Writing a Letter)** - (\"entity\"<|>写封信<|>ACTION<|>Writing a letter is an action described in the text)\n5. **不贴邮票 (Not Putting Postage Stamps)** - (\"entity\"<|>不贴邮票<|>ACTION<|>Not putting postage stamps is an action mentioned in the text)\n6. **谁给你寄? (Who Will Give You a Letter?)** - (\"entity\"<|>谁给你寄?<|>INTERROGATION<|>Who will give you a letter?)\n7. **爷爷 (Grandfather)** - (\"entity\"<|>爷爷<|>PERSON<|>Grandfather is a person mentioned in the text)\n8. **风一吹 (Wind Blows)** - (\"entity\"<|>风一吹<|>ACTION<|>The wind blows is an action described in the text)\n\n### Relationships:\n\n1. **Vanilla Cake and Poor Little Boy are related** - (\"relationship\"<|>凡卡<|>POOR LITTLE BOY<|>Vanilla Cake and Poor Little Boy are clearly related because Vanilla Cake wrote a letter to his grandfather, Poor Little Boy)\n2. **Poor Little Boy and Doomed to Live are related** - (\"relationship\"<|>凡卡<|>DOOMED TO LIVE<|>POOR LITTLE BOY<|>Poor Little Boy is an event mentioned in the text, so they are clearly related because Poor Little Boy was written about in the text)\n3. **Doomed to Live and Writing a Letter are related** - (\"relationship\"<|>DOOMED TO LIVE<|>WRITING A LETTER<|>Writing a letter is an action described in the text, so they are clearly related because writing a letter is part of the process of Doomed to Live)\n4. **Vanilla Cake and Who Will Give You a Letter? are related** - (\"relationship\"<|>凡卡<|>WHO WILL GIVE YOU A LETTER?<|>INTERROGATION<|>Who will give you a letter?)\n5. **Poor Little Boy and Who Will Give You a Letter? are related** - (\"relationship\"<|>POOR LITTLE BOY<|>WHO WILL GIVE YOU A LETTER?<|>INTERROGATION<|>Who will give you a letter?\")\n6. **Doomed to Live and Who Will Give You a Letter? are related** - (\"relationship\"<|>DOOMED TO LIVE<|>WHO WILL GIVE YOU A LETTER?<|>INTERROGATION<|>Who will give you a letter?\")\n7. **Writing a Letter and Who Will Give You a Letter? are related** - (\"relationship\"<|>WRITING A LETTER<|>WHO WILL GIVE YOU A LETTER?<|>INTERROGATION<|>Who will give you a letter?\")\n8. **Vanilla Cake, Poor Little Boy, and Who Will Give You a Letter? are all related to the same event** - (\"relationship\"<|>凡卡<|>POOR LITTLE BOY<|>WHO WILL GIVE YOU A LETTER?<|>INTERROGATION<|>Who will give you a letter?\")\n9. **Vanilla Cake, Poor Little Boy, and Doomed to Live are all related to the same event** - (\"relationship\"<|>凡卡<|>POOR LITTLE BOY<|>DOOMED TO LIVE<|>Vanilla Cake wrote a letter to his grandfather, Poor Little Boy is an event mentioned in the text, so they are clearly related because Poor Little Boy was written about in the text)\n10. **Poor Little Boy and Doomed to Live are all related to the same person** - (\"relationship\"<|>凡卡<|>POOR LITTLE BOY<|>DOOMED TO LIVE<|>Vanilla Cake wrote a letter to his grandfather, Poor Little Boy is an event mentioned in the text, so they are clearly related because Poor Little Boy was written about in the text)\n\n### Output:\n\n## ## [\"entity\"<|>凡卡<|>PERSON<|>Vanilla Cake is a person who wrote a letter to his grandfather\", \n \"entity\"<|>凡卡<|>PERSON<|>Poor Little Boy is an organization that was written about in the text\", \n \"entity\"<|>凡卡<|>ORGANIZATION<|>Vanilla Cake is an organization that wrote a letter to his grandfather\", \n \"entity\"<|> Poor Little Boy is an event mentioned in the text\", \n \"entity\"<|> Poor Little Boy is an action described in the text\", \n \"entity\"<|> Poor Little Boy is part of the process of Doomed to Live\", \n \"entity\"<|> Poor Little Boy is clearly related to Doomed to Live because Poor Little Boy was written about in the text\", \n \"entity\"<|> Poor Little Boy and Who Will Give You a Letter? are clearly related because Poor Little Boy was written about in the text\", \n \"entity\"<|> Poor Little Boy and Who Will Give You a Letter? are part of the same event\", \n \"entity\"<|> Poor Little Boy and Doomed to Live are part of the same person\", \n \"entity\"<|> Poor Little Boy is clearly related to Doomed to Live because Poor Little Boy was written about in the text\", \n \"entity\"<|> Poor Little Boy and Who Will Give You a Letter? are all related to the same event\", \n \"entity\"<|> Poor Little Boy, Vanilla Cake, and Who Will Give You a Letter? are all clearly related to Doomed to Live because Poor Little Boy was written about in the text\"]\n\n## <|COMPLETE|>"
                }
            ],
            "name": "extract-continuation-0"
        }
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n    yield\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 394, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 256, in handle_async_request\n    raise exc from None\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 236, in handle_async_request\n    response = await connection.handle_async_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 103, in handle_async_request\n    return await self._connection.handle_async_request(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 136, in handle_async_request\n    raise exc\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 106, in handle_async_request\n    ) = await self._receive_response_headers(**kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 177, in _receive_response_headers\n    event = await self._receive_event(timeout=timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 217, in _receive_event\n    data = await self._network_stream.read(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 32, in read\n    with map_exceptions(exc_map):\n  File \"D:\\app\\AnaConda\\Lib\\contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    response = await self._client.send(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_client.py\", line 1629, in send\n    response = await self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_client.py\", line 1657, in _send_handling_auth\n    response = await self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_client.py\", line 1694, in _send_handling_redirects\n    response = await self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_client.py\", line 1730, in _send_single_request\n    response = await transport.handle_async_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 393, in handle_async_request\n    with map_httpcore_exceptions():\n  File \"D:\\app\\AnaConda\\Lib\\contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 118, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\index\\operations\\extract_graph\\graph_extractor.py\", line 158, in _process_document\n    response = await self._model.achat(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\language_model\\providers\\fnllm\\models.py\", line 84, in achat\n    response = await self.model(prompt, history=history, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_chat_llm.py\", line 94, in __call__\n    return await self._text_chat_llm(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\openai\\services\\openai_tools_parsing.py\", line 130, in __call__\n    return await self._delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 137, in invoke\n    result = await delegate(prompt, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\rate_limiter.py\", line 75, in invoke\n    result = await delegate(prompt, **args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 126, in _decorator_target\n    output = await self._execute_llm(prompt, kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_text_chat_llm.py\", line 166, in _execute_llm\n    raw_response = await self._client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\_legacy_response.py\", line 381, in wrapped\n    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2454, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\_base_client.py\", line 1784, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    raise APITimeoutError(request=request) from err\nopenai.APITimeoutError: Request timed out.\n",
    "source": "Request timed out.",
    "details": {
        "doc_index": 0,
        "text": "而是轻蔑地对凡卡说：“穷小子，撞死活该！写封信——不贴邮票，不写收信人地址，谁给你寄！”\n\n说完，便用手一撕，再一撕，再撕，再撕……手一扬，风一吹，凡卡给爷爷写的信"
    }
}
{
    "type": "error",
    "data": "Community Report Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 139, in _read_model_from_json\n    return json_model.model_validate(value)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\pydantic\\main.py\", line 705, in model_validate\n    return cls.__pydantic_validator__.validate_python(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\npydantic_core._pydantic_core.ValidationError: 1 validation error for CommunityReportResponse\nrating\n  Field required [type=missing, input_value={'title': 'Firuzabad Comm...nced social welfare.'}]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 96, in invoke_json\n    return await self.try_receive_json(delegate, prompt, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 115, in try_receive_json\n    model = self._read_model_from_json(raw_json, json_model)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 142, in _read_model_from_json\n    raise FailedToGenerateValidJsonError(msg) from err\nfnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response does not match the expected model, response={'title': 'Firuzabad Community Overview', 'summary': 'This community overview provides an executive summary of its key entities, relationships, and significant information associated with them.', 'impact_severity_rating': 8.5, 'rating_explanation': 'The Firuzabad community is a complex network of individuals, organizations, and institutions that interact with each other in various ways. The severity of IMPACT posed by this community can be attributed to its diverse range of entities, including governments, businesses, and non-profit organizations.', 'findings': [{'summary': 'The Firuzabad community is comprised of multiple entities, including governments, businesses, and non-profit organizations. These entities interact with each other in various ways, resulting in a complex web of relationships and interactions.', 'explanation': 'The Firuzabad community is characterized by its diverse range of entities, which include governments, businesses, and non-profit organizations. These entities interact with each other through various means, such as trade, investment, and collaboration. The complexity of these relationships can be attributed to the presence of multiple stakeholders, including individuals, organizations, and institutions.', 'insight_1_summary': 'The Firuzabad community is a complex network of individuals, organizations, and institutions that interact with each other in various ways.', 'insight_1_explanation': 'This complexity arises from the diverse range of entities within the community, including governments, businesses, and non-profit organizations. These entities have different goals, motivations, and priorities, which can lead to conflicts and challenges in maintaining stability and cooperation.'}, {'summary': 'The Firuzabad community is characterized by its strong relationships between governments and businesses. These relationships are often driven by economic interests, such as trade agreements and investment opportunities.', 'explanation': 'The presence of strong relationships between governments and businesses can be attributed to the economic benefits that these partnerships provide. Governments may seek to attract foreign investment and promote economic growth through trade agreements, while businesses may seek to expand their operations and increase profits through collaborations with government entities.', 'insight_2_summary': 'The Firuzabad community is characterized by its strong relationships between governments and businesses.', 'insight_2_explanation': 'These relationships are often driven by economic interests, such as trade agreements and investment opportunities. The presence of these relationships can lead to conflicts and challenges in maintaining stability and cooperation within the community.'}, {'summary': 'The Firuzabad community is also characterized by its complex relationships with non-profit organizations. These organizations often provide social services and support to vulnerable populations, which can create tensions between governments and businesses.', 'explanation': 'The presence of complex relationships with non-profit organizations can be attributed to the diverse range of services they provide. Non-profit organizations may seek to promote social welfare and address issues such as poverty and inequality, while governments may seek to regulate or control these activities.', 'insight_3_summary': 'The Firuzabad community is characterized by its complex relationships with non-profit organizations.', 'insight_3_explanation': 'These relationships can create tensions between governments and businesses, particularly when it comes to issues such as regulation and control. The presence of non-profit organizations can lead to conflicts over the allocation of resources and the distribution of services.'}, {'summary': 'The Firuzabad community is also characterized by its strong relationships with international organizations. These organizations often provide technical assistance and support to governments and businesses, which can help to address global challenges such as climate change and economic development.', 'explanation': 'The presence of strong relationships with international organizations can be attributed to the need for cooperation and collaboration in addressing global challenges. International organizations may seek to promote economic growth, reduce poverty, and improve living standards through their activities.', 'insight_4_summary': 'The Firuzabad community is characterized by its strong relationships with international organizations.', 'insight_4_explanation': 'These relationships are often driven by the need for cooperation and collaboration in addressing global challenges. The presence of these relationships can lead to benefits such as increased economic growth, improved living standards, and enhanced social welfare.'}]}.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 77, in invoke\n    return await this.invoke_json(delegate, prompt, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 100, in invoke_json\n    raise FailedToGenerateValidJsonError from error\nfnllm.base.services.errors.FailedToGenerateValidJsonError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\index\\operations\\summarize_communities\\community_reports_extractor.py\", line 80, in __call__\n    response = await self._model.achat(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\language_model\\providers\\fnllm\\models.py\", line 82, in achat\n    response = await self.model(prompt, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_chat_llm.py\", line 94, in __call__\n    return await self._text_chat_llm(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\openai\\services\\openai_tools_parsing.py\", line 130, in __call__\n    return await self._delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 148, in __call__\n    await self._events.on_error(\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\language_model\\providers\\fnllm\\events.py\", line 26, in on_error\n    self._on_error(error, traceback, arguments)\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\language_model\\providers\\fnllm\\utils.py\", line 45, in on_error\n    callbacks.error(\"Error Invoking LLM\", error, stack, details)\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\callbacks\\workflow_callbacks_manager.py\", line 64, in error\n    callback.error(message, cause, stack, details)\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\callbacks\\file_workflow_callbacks.py\", line 37, in error\n    json.dumps(\n  File \"D:\\app\\AnaConda\\Lib\\json\\__init__.py\", line 238, in dumps\n    **kw).encode(obj)\n          ^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\json\\encoder.py\", line 202, in encode\n    chunks = list(chunks)\n             ^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\json\\encoder.py\", line 432, in _iterencode\n    yield from _iterencode_dict(o, _current_indent_level)\n  File \"D:\\app\\AnaConda\\Lib\\json\\encoder.py\", line 406, in _iterencode_dict\n    yield from chunks\n  File \"D:\\app\\AnaConda\\Lib\\json\\encoder.py\", line 406, in _iterencode_dict\n    yield from chunks\n  File \"D:\\app\\AnaConda\\Lib\\json\\encoder.py\", line 406, in _iterencode_dict\n    yield from chunks\n  File \"D:\\app\\AnaConda\\Lib\\json\\encoder.py\", line 439, in _iterencode\n    o = _default(o)\n        ^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\json\\encoder.py\", line 180, in default\n    raise TypeError(f'Object of type {o.__class__.__name__} '\nTypeError: Object of type ModelMetaclass is not JSON serializable\n",
    "source": "Object of type ModelMetaclass is not JSON serializable",
    "details": null
}
{
    "type": "error",
    "data": "Community Report Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n    yield\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 394, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 256, in handle_async_request\n    raise exc from None\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 236, in handle_async_request\n    response = await connection.handle_async_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 103, in handle_async_request\n    return await self._connection.handle_async_request(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 136, in handle_async_request\n    raise exc\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 106, in handle_async_request\n    ) = await self._receive_response_headers(**kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 177, in _receive_response_headers\n    event = await self._receive_event(timeout=timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 217, in _receive_event\n    data = await self._network_stream.read(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 32, in read\n    with map_exceptions(exc_map):\n  File \"D:\\app\\AnaConda\\Lib\\contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    response = await self._client.send(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_client.py\", line 1629, in send\n    response = await self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_client.py\", line 1657, in _send_handling_auth\n    response = await self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_client.py\", line 1694, in _send_handling_redirects\n    response = await self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_client.py\", line 1730, in _send_single_request\n    response = await transport.handle_async_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 393, in handle_async_request\n    with map_httpcore_exceptions():\n  File \"D:\\app\\AnaConda\\Lib\\contextlib.py\", line 155, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 77, in invoke\n    return await this.invoke_json(delegate, prompt, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 96, in invoke_json\n    return await self.try_receive_json(delegate, prompt, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\json.py\", line 112, in try_receive_json\n    result = await delegate(prompt, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 121, in invoke\n    result = await delegate(prompt, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\services\\rate_limiter.py\", line 75, in invoke\n    result = await delegate(prompt, **args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 126, in _decorator_target\n    output = await self._execute_llm(prompt, kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_text_chat_llm.py\", line 166, in _execute_llm\n    raw_response = await self._client.chat.completions.with_raw_response.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\_legacy_response.py\", line 381, in wrapped\n    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))\n                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2454, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\_base_client.py\", line 1784, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\openai\\_base_client.py\", line 1537, in request\n    raise APITimeoutError(request=request) from err\nopenai.APITimeoutError: Request timed out.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\index\\operations\\summarize_communities\\community_reports_extractor.py\", line 80, in __call__\n    response = await self._model.achat(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\language_model\\providers\\fnllm\\models.py\", line 82, in achat\n    response = await self.model(prompt, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\openai\\llm\\openai_chat_llm.py\", line 94, in __call__\n    return await self._text_chat_llm(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\openai\\services\\openai_tools_parsing.py\", line 130, in __call__\n    return await self._delegate(prompt, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\site-packages\\fnllm\\base\\base_llm.py\", line 148, in __call__\n    await self._events.on_error(\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\language_model\\providers\\fnllm\\events.py\", line 26, in on_error\n    self._on_error(error, traceback, arguments)\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\language_model\\providers\\fnllm\\utils.py\", line 45, in on_error\n    callbacks.error(\"Error Invoking LLM\", error, stack, details)\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\callbacks\\workflow_callbacks_manager.py\", line 64, in error\n    callback.error(message, cause, stack, details)\n  File \"G:\\code\\online-code\\env-data\\data\\ZeroGraphRAG\\graphrag\\graphrag\\callbacks\\file_workflow_callbacks.py\", line 37, in error\n    json.dumps(\n  File \"D:\\app\\AnaConda\\Lib\\json\\__init__.py\", line 238, in dumps\n    **kw).encode(obj)\n          ^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\json\\encoder.py\", line 202, in encode\n    chunks = list(chunks)\n             ^^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\json\\encoder.py\", line 432, in _iterencode\n    yield from _iterencode_dict(o, _current_indent_level)\n  File \"D:\\app\\AnaConda\\Lib\\json\\encoder.py\", line 406, in _iterencode_dict\n    yield from chunks\n  File \"D:\\app\\AnaConda\\Lib\\json\\encoder.py\", line 406, in _iterencode_dict\n    yield from chunks\n  File \"D:\\app\\AnaConda\\Lib\\json\\encoder.py\", line 406, in _iterencode_dict\n    yield from chunks\n  File \"D:\\app\\AnaConda\\Lib\\json\\encoder.py\", line 439, in _iterencode\n    o = _default(o)\n        ^^^^^^^^^^^\n  File \"D:\\app\\AnaConda\\Lib\\json\\encoder.py\", line 180, in default\n    raise TypeError(f'Object of type {o.__class__.__name__} '\nTypeError: Object of type ModelMetaclass is not JSON serializable\n",
    "source": "Object of type ModelMetaclass is not JSON serializable",
    "details": null
}
