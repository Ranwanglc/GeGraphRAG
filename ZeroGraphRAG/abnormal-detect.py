#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¼‚å¸¸IPåˆ†ç±»æŸ¥è¯¢ç³»ç»Ÿ
ä½¿ç”¨GraphRAGå’Œå¤§æ¨¡å‹è¿›è¡Œå¼‚å¸¸IPåˆ†ç±»ï¼Œå¹¶è®¡ç®—å‡†ç¡®ç‡

ä½œè€…: WebSWEAgent
æ—¥æœŸ: 2025-08-10
"""

import os
import json
import pandas as pd
import subprocess
import requests
import time
from pathlib import Path
from collections import defaultdict
import re

class AnomalyIPClassifier:
    def __init__(self, graphrag_workspace="graphrag_workspace"):
        """
        åˆå§‹åŒ–å¼‚å¸¸IPåˆ†ç±»å™¨
        """
        self.workspace = Path(graphrag_workspace)
        self.ollama_base_url = "http://localhost:11434"
        
        # å¼‚å¸¸ç±»å‹æ˜ å°„
        self.anomaly_type_mapping = {
            'botnet_c2': 'Botnet C&Cé€šä¿¡',
            'dns_tunneling': 'DNSéš§é“',
            'malware_communication': 'æ¶æ„è½¯ä»¶é€šä¿¡',
            'data_exfiltration': 'æ•°æ®æ³„éœ²',
            'reconnaissance': 'ç½‘ç»œä¾¦å¯Ÿ',
            'phishing': 'é’“é±¼æ”»å‡»',
            'normal': 'æ­£å¸¸',
            'unknown_anomaly': 'æœªçŸ¥å¼‚å¸¸'
        }
        
        # æŸ¥è¯¢æ¨¡æ¿
        self.query_templates = {
            'classification': """
è¯·åˆ†æIPåœ°å€ {ip_address} çš„å¼‚å¸¸è¡Œä¸ºç±»å‹ã€‚

åŸºäºä»¥ä¸‹ä¿¡æ¯è¿›è¡Œåˆ†æï¼š
- è¯¥IPçš„DNSæŸ¥è¯¢è¡Œä¸ºæ¨¡å¼
- ç½‘ç»œé€šä¿¡ç‰¹å¾
- æ—¶é—´è¡Œä¸ºæ¨¡å¼
- å·²çŸ¥çš„å®‰å…¨å¨èƒæŒ‡æ ‡

è¯·ä»ä»¥ä¸‹ç±»å‹ä¸­é€‰æ‹©æœ€åŒ¹é…çš„å¼‚å¸¸ç±»å‹ï¼š
1. Botnet C&Cé€šä¿¡ - åƒµå°¸ç½‘ç»œæ§åˆ¶æœåŠ¡å™¨é€šä¿¡
2. DNSéš§é“ - DNSéš§é“æ•°æ®æ³„éœ²
3. æ¶æ„è½¯ä»¶é€šä¿¡ - æ¶æ„è½¯ä»¶ä¸è¿œç¨‹æœåŠ¡å™¨é€šä¿¡
4. æ•°æ®æ³„éœ² - æ•°æ®å¤–æ³„è¡Œä¸º
5. ç½‘ç»œä¾¦å¯Ÿ - ç½‘ç»œä¾¦å¯Ÿæ´»åŠ¨
6. é’“é±¼æ”»å‡» - é’“é±¼ç½‘ç«™è®¿é—®
7. æœªçŸ¥å¼‚å¸¸ - å…¶ä»–ç±»å‹çš„å¼‚å¸¸è¡Œä¸º

è¯·æä¾›ï¼š
1. å¼‚å¸¸ç±»å‹åˆ†ç±»ç»“æœ
2. ç½®ä¿¡åº¦è¯„åˆ†ï¼ˆ0-1ï¼‰
3. ä¸»è¦åˆ¤æ–­ä¾æ®
4. å»ºè®®çš„å®‰å…¨æªæ–½

æ ¼å¼è¦æ±‚ï¼š
å¼‚å¸¸ç±»å‹ï¼š[å…·ä½“ç±»å‹]
ç½®ä¿¡åº¦ï¼š[0-1çš„æ•°å€¼]
åˆ¤æ–­ä¾æ®ï¼š[è¯¦ç»†è¯´æ˜]
å®‰å…¨å»ºè®®ï¼š[å…·ä½“å»ºè®®]
""",
            
            'detailed_analysis': """
è¯·å¯¹IPåœ°å€ {ip_address} è¿›è¡Œè¯¦ç»†çš„å®‰å…¨åˆ†æã€‚

åˆ†æè¦ç‚¹ï¼š
1. DNSæŸ¥è¯¢è¡Œä¸ºæ˜¯å¦å¼‚å¸¸
2. ç½‘ç»œé€šä¿¡æ¨¡å¼åˆ†æ
3. æ—¶é—´è¡Œä¸ºç‰¹å¾
4. ä¸å·²çŸ¥å¨èƒçš„å…³è”æ€§
5. æ½œåœ¨çš„å®‰å…¨é£é™©

è¯·æä¾›å…¨é¢çš„åˆ†ææŠ¥å‘Šã€‚
""",
            
            'batch_classification': """
è¯·å¯¹ä»¥ä¸‹å¼‚å¸¸IPåœ°å€è¿›è¡Œæ‰¹é‡åˆ†ç±»åˆ†æï¼š
{ip_list}

å¯¹æ¯ä¸ªIPï¼Œè¯·æä¾›ï¼š
1. å¼‚å¸¸ç±»å‹
2. ç½®ä¿¡åº¦
3. ä¸»è¦ç‰¹å¾

æ ¼å¼ï¼š
IP: [åœ°å€] | ç±»å‹: [å¼‚å¸¸ç±»å‹] | ç½®ä¿¡åº¦: [æ•°å€¼] | ç‰¹å¾: [ç®€è¦æè¿°]
"""
        }
    
    def query_graphrag(self, query, method="global"):
        """
        æŸ¥è¯¢GraphRAGç³»ç»Ÿ
        """
        try:
            original_dir = os.getcwd()
            os.chdir(self.workspace)
            
            # Windowsä¸‹éœ€è¦æŒ‡å®šç¼–ç 
            result = subprocess.run(
                ["python", "-m", "graphrag.query", 
                 "--root", ".", 
                 "--method", method,
                 query],
                capture_output=True,
                text=True,
                encoding='utf-8',  # æ˜ç¡®æŒ‡å®šUTF-8ç¼–ç 
                errors='ignore',   # å¿½ç•¥ç¼–ç é”™è¯¯
                timeout=120
            )
            
            if result.returncode == 0:
                return result.stdout.strip()
            else:
                # å°è¯•ä¸åŒç¼–ç è¯»å–é”™è¯¯ä¿¡æ¯
                error_msg = result.stderr
                if not error_msg:
                    try:
                        # å¦‚æœstderrä¸ºç©ºï¼Œå°è¯•ç”¨gbkè§£ç 
                        error_msg = result.stderr.encode('utf-8').decode('gbk', errors='ignore')
                    except:
                        error_msg = "ç¼–ç é”™è¯¯ï¼Œæ— æ³•æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯"
                
                print(f"GraphRAGæŸ¥è¯¢å¤±è´¥: {error_msg}")
                return None
                
        except subprocess.TimeoutExpired:
            print("GraphRAGæŸ¥è¯¢è¶…æ—¶")
            return None
        except UnicodeDecodeError as e:
            print(f"ç¼–ç é”™è¯¯: {e}")
            print("å°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•...")
            return self._query_graphrag_fallback(query, method)
        except Exception as e:
            print(f"GraphRAGæŸ¥è¯¢å‡ºé”™: {e}")
            return None
        finally:
            os.chdir(original_dir)
    
    def _query_graphrag_fallback(self, query, method="global"):
        """
        GraphRAGæŸ¥è¯¢çš„å¤‡ç”¨æ–¹æ³•ï¼ˆå¤„ç†ç¼–ç é—®é¢˜ï¼‰
        """
        try:
            original_dir = os.getcwd()
            os.chdir(self.workspace)
            
            # ä½¿ç”¨bytesæ¨¡å¼é¿å…ç¼–ç é—®é¢˜
            result = subprocess.run(
                ["python", "-m", "graphrag.query", 
                 "--root", ".", 
                 "--method", method,
                 query],
                capture_output=True,
                timeout=120
            )
            
            if result.returncode == 0:
                # å°è¯•å¤šç§ç¼–ç è§£ç è¾“å‡º
                output = None
                for encoding in ['utf-8', 'gbk', 'cp936', 'latin1']:
                    try:
                        output = result.stdout.decode(encoding)
                        break
                    except UnicodeDecodeError:
                        continue
                
                if output:
                    return output.strip()
                else:
                    print("æ— æ³•è§£ç GraphRAGè¾“å‡º")
                    return None
            else:
                print("GraphRAGæŸ¥è¯¢å¤±è´¥ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰")
                return None
                
        except Exception as e:
            print(f"å¤‡ç”¨æŸ¥è¯¢æ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
            return None
        finally:
            os.chdir(original_dir)
    
    def query_ollama_direct(self, prompt, model="qwen2.5:7b"):
        """
        ç›´æ¥æŸ¥è¯¢ollamaæ¨¡å‹
        """
        try:
            response = requests.post(
                f"{self.ollama_base_url}/api/generate",
                json={
                    "model": model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.1,
                        "top_p": 0.9
                    }
                },
                timeout=60
            )
            
            if response.status_code == 200:
                return response.json().get('response', '')
            else:
                print(f"OllamaæŸ¥è¯¢å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"OllamaæŸ¥è¯¢å‡ºé”™: {e}")
            return None
    
    def classify_single_ip(self, ip_address, use_graphrag=True):
        """
        åˆ†ç±»å•ä¸ªIPåœ°å€
        """
        print(f"æ­£åœ¨åˆ†æIP: {ip_address}")
        
        # æ„å»ºæŸ¥è¯¢
        query = self.query_templates['classification'].format(ip_address=ip_address)
        
        # ä½¿ç”¨GraphRAGæŸ¥è¯¢
        if use_graphrag:
            response = self.query_graphrag(query)
        else:
            response = self.query_ollama_direct(query)
        
        if not response:
            return {
                'ip': ip_address,
                'anomaly_type': 'unknown_anomaly',
                'confidence': 0.0,
                'reasoning': 'æŸ¥è¯¢å¤±è´¥',
                'recommendations': 'éœ€è¦æ‰‹åŠ¨åˆ†æ'
            }
        
        # è§£æå“åº”
        result = self.parse_classification_response(response)
        result['ip'] = ip_address
        result['raw_response'] = response
        
        return result
    
    def parse_classification_response(self, response):
        """
        è§£æåˆ†ç±»å“åº”
        """
        result = {
            'anomaly_type': 'unknown_anomaly',
            'confidence': 0.0,
            'reasoning': '',
            'recommendations': ''
        }
        
        try:
            # æå–å¼‚å¸¸ç±»å‹
            type_match = re.search(r'å¼‚å¸¸ç±»å‹[ï¼š:]\s*([^\n]+)', response)
            if type_match:
                type_text = type_match.group(1).strip()
                # æ˜ å°„åˆ°æ ‡å‡†ç±»å‹
                for key, value in self.anomaly_type_mapping.items():
                    if value in type_text or key in type_text.lower():
                        result['anomaly_type'] = key
                        break
            
            # æå–ç½®ä¿¡åº¦
            confidence_match = re.search(r'ç½®ä¿¡åº¦[ï¼š:]\s*([0-9.]+)', response)
            if confidence_match:
                result['confidence'] = float(confidence_match.group(1))
            
            # æå–åˆ¤æ–­ä¾æ®
            reasoning_match = re.search(r'åˆ¤æ–­ä¾æ®[ï¼š:]\s*([^\n]+(?:\n[^ï¼š:]*)*)', response)
            if reasoning_match:
                result['reasoning'] = reasoning_match.group(1).strip()
            
            # æå–å®‰å…¨å»ºè®®
            recommendations_match = re.search(r'å®‰å…¨å»ºè®®[ï¼š:]\s*([^\n]+(?:\n[^ï¼š:]*)*)', response)
            if recommendations_match:
                result['recommendations'] = recommendations_match.group(1).strip()
        
        except Exception as e:
            print(f"è§£æå“åº”æ—¶å‡ºé”™: {e}")
        
        return result
    
    def classify_batch_ips(self, ip_list, use_graphrag=True, batch_size=5):
        """
        æ‰¹é‡åˆ†ç±»IPåœ°å€
        """
        print(f"å¼€å§‹æ‰¹é‡åˆ†æ {len(ip_list)} ä¸ªIPåœ°å€")
        
        results = []
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(ip_list), batch_size):
            batch = ip_list[i:i+batch_size]
            print(f"å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}: {len(batch)} ä¸ªIP")
            
            for ip in batch:
                result = self.classify_single_ip(ip, use_graphrag)
                results.append(result)
                
                # æ·»åŠ å»¶è¿Ÿé¿å…è¿‡è½½
                time.sleep(1)
        
        return results
    
    def load_ground_truth_from_csv(self, abnormal_ips_file):
        """
        ä»abnormal_ips.csvæ–‡ä»¶åŠ è½½çœŸå®åˆ†ç±»æ ‡ç­¾
        ç¬¬ä¸€åˆ—ï¼šIPåœ°å€ï¼Œç¬¬äºŒåˆ—ï¼šå¼‚å¸¸ç±»å‹æ ‡ç­¾
        """
        try:
            df = pd.read_csv(abnormal_ips_file, encoding='utf-8')
            
            if df.shape[1] < 2:
                print("âŒ abnormal_ips.csvæ–‡ä»¶ç¼ºå°‘ç¬¬äºŒåˆ—ï¼ˆå¼‚å¸¸ç±»å‹æ ‡ç­¾ï¼‰")
                return {}
            
            ground_truth = {}
            
            # è¯»å–ç¬¬ä¸€åˆ—ï¼ˆIPåœ°å€ï¼‰å’Œç¬¬äºŒåˆ—ï¼ˆå¼‚å¸¸ç±»å‹ï¼‰
            for idx, row in df.iterrows():
                ip_address = str(row.iloc[0]).strip()
                anomaly_type = str(row.iloc[1]).strip()
                
                if ip_address and ip_address != 'nan' and anomaly_type and anomaly_type != 'nan':
                    # æ ‡å‡†åŒ–å¼‚å¸¸ç±»å‹åç§°
                    normalized_type = self.normalize_anomaly_type(anomaly_type)
                    
                    ground_truth[ip_address] = {
                        'type': normalized_type,
                        'description': self.anomaly_type_mapping.get(normalized_type, anomaly_type)
                    }
            
            print(f"âœ… ä»CSVæ–‡ä»¶åŠ è½½äº† {len(ground_truth)} ä¸ªIPçš„çœŸå®æ ‡ç­¾")
            
            # æ˜¾ç¤ºæ ‡ç­¾åˆ†å¸ƒ
            type_counts = {}
            for gt in ground_truth.values():
                type_name = gt['type']
                type_counts[type_name] = type_counts.get(type_name, 0) + 1
            
            print("çœŸå®æ ‡ç­¾åˆ†å¸ƒ:")
            for anomaly_type, count in type_counts.items():
                type_name = self.anomaly_type_mapping.get(anomaly_type, anomaly_type)
                print(f"  {type_name}: {count}")
            
            return ground_truth
            
        except Exception as e:
            print(f"âŒ ä»CSVåŠ è½½çœŸå®æ ‡ç­¾å¤±è´¥: {e}")
            return {}
    
    def normalize_anomaly_type(self, type_text):
        """
        æ ‡å‡†åŒ–å¼‚å¸¸ç±»å‹åç§°
        """
        type_text = type_text.lower().strip()
        
        # æ˜ å°„å¸¸è§çš„å¼‚å¸¸ç±»å‹åç§°åˆ°æ ‡å‡†åç§°
        type_mapping = {
            # Botnet C&C
            'botnet': 'botnet_c2',
            'botnet_c2': 'botnet_c2',
            'botnet_cc': 'botnet_c2',
            'c2': 'botnet_c2',
            'cc': 'botnet_c2',
            'åƒµå°¸ç½‘ç»œ': 'botnet_c2',
            
            # DNSéš§é“
            'dns_tunnel': 'dns_tunneling',
            'dns_tunneling': 'dns_tunneling',
            'tunnel': 'dns_tunneling',
            'dnséš§é“': 'dns_tunneling',
            'éš§é“': 'dns_tunneling',
            
            # æ¶æ„è½¯ä»¶é€šä¿¡
            'malware': 'malware_communication',
            'malware_communication': 'malware_communication',
            'malware_comm': 'malware_communication',
            'æ¶æ„è½¯ä»¶': 'malware_communication',
            'æœ¨é©¬': 'malware_communication',
            
            # æ•°æ®æ³„éœ²
            'data_exfiltration': 'data_exfiltration',
            'exfiltration': 'data_exfiltration',
            'data_leak': 'data_exfiltration',
            'æ•°æ®æ³„éœ²': 'data_exfiltration',
            'æ•°æ®å¤–æ³„': 'data_exfiltration',
            
            # ç½‘ç»œä¾¦å¯Ÿ
            'reconnaissance': 'reconnaissance',
            'recon': 'reconnaissance',
            'scanning': 'reconnaissance',
            'ä¾¦å¯Ÿ': 'reconnaissance',
            'æ‰«æ': 'reconnaissance',
            
            # é’“é±¼æ”»å‡»
            'phishing': 'phishing',
            'phish': 'phishing',
            'é’“é±¼': 'phishing',
            
            # æ­£å¸¸
            'normal': 'normal',
            'benign': 'normal',
            'æ­£å¸¸': 'normal',
            
            # æœªçŸ¥å¼‚å¸¸
            'unknown': 'unknown_anomaly',
            'unknown_anomaly': 'unknown_anomaly',
            'other': 'unknown_anomaly',
            'æœªçŸ¥': 'unknown_anomaly',
            'å…¶ä»–': 'unknown_anomaly'
        }
        
        return type_mapping.get(type_text, 'unknown_anomaly')
    
    def create_ground_truth_file(self, anomaly_ips, output_file="ground_truth_classifications.json"):
        """
        åˆ›å»ºçœŸå®åˆ†ç±»æ ‡ç­¾æ–‡ä»¶ï¼ˆç¤ºä¾‹ï¼‰
        """
        print("åˆ›å»ºç¤ºä¾‹çœŸå®åˆ†ç±»æ ‡ç­¾æ–‡ä»¶...")
        
        # ç¤ºä¾‹åˆ†ç±»ï¼ˆå®é™…ä½¿ç”¨æ—¶éœ€è¦æ ¹æ®çœŸå®æƒ…å†µæ ‡æ³¨ï¼‰
        ground_truth = {}
        
        for i, ip in enumerate(anomaly_ips):
            # è¿™é‡Œæ˜¯ç¤ºä¾‹åˆ†ç±»ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦ä¸“å®¶æ ‡æ³¨
            if i % 6 == 0:
                ground_truth[ip] = {
                    'type': 'botnet_c2',
                    'description': 'Botnet C&Cé€šä¿¡'
                }
            elif i % 6 == 1:
                ground_truth[ip] = {
                    'type': 'dns_tunneling',
                    'description': 'DNSéš§é“'
                }
            elif i % 6 == 2:
                ground_truth[ip] = {
                    'type': 'malware_communication',
                    'description': 'æ¶æ„è½¯ä»¶é€šä¿¡'
                }
            elif i % 6 == 3:
                ground_truth[ip] = {
                    'type': 'data_exfiltration',
                    'description': 'æ•°æ®æ³„éœ²'
                }
            elif i % 6 == 4:
                ground_truth[ip] = {
                    'type': 'reconnaissance',
                    'description': 'ç½‘ç»œä¾¦å¯Ÿ'
                }
            else:
                ground_truth[ip] = {
                    'type': 'phishing',
                    'description': 'é’“é±¼æ”»å‡»'
                }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(ground_truth, f, ensure_ascii=False, indent=2)
        
        print(f"ç¤ºä¾‹çœŸå®æ ‡ç­¾æ–‡ä»¶å·²åˆ›å»º: {output_file}")
        print("æ³¨æ„ï¼šè¿™æ˜¯ç¤ºä¾‹æ•°æ®ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦ä¸“å®¶è¿›è¡Œå‡†ç¡®æ ‡æ³¨")
        
        return ground_truth
    
    def calculate_accuracy(self, predictions, ground_truth):
        """
        è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡
        """
        if not predictions or not ground_truth:
            print("é¢„æµ‹ç»“æœæˆ–çœŸå®æ ‡ç­¾ä¸ºç©º")
            return {}
        
        # ç»Ÿè®¡ç»“æœ
        total = 0
        correct = 0
        type_stats = defaultdict(lambda: {'total': 0, 'correct': 0})
        
        for pred in predictions:
            ip = pred['ip']
            pred_type = pred['anomaly_type']
            
            if ip in ground_truth:
                total += 1
                true_type = ground_truth[ip]['type']
                
                type_stats[true_type]['total'] += 1
                
                if pred_type == true_type:
                    correct += 1
                    type_stats[true_type]['correct'] += 1
        
        # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
        overall_accuracy = correct / total if total > 0 else 0
        
        # è®¡ç®—å„ç±»å‹å‡†ç¡®ç‡
        type_accuracies = {}
        for anomaly_type, stats in type_stats.items():
            if stats['total'] > 0:
                type_accuracies[anomaly_type] = stats['correct'] / stats['total']
            else:
                type_accuracies[anomaly_type] = 0
        
        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        confidences = [pred['confidence'] for pred in predictions if pred['confidence'] > 0]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0
        
        return {
            'overall_accuracy': overall_accuracy,
            'total_samples': total,
            'correct_predictions': correct,
            'type_accuracies': type_accuracies,
            'average_confidence': avg_confidence,
            'type_statistics': dict(type_stats)
        }
    
    def generate_evaluation_report(self, predictions, ground_truth, output_file="evaluation_report.json"):
        """
        ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
        """
        print("ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š...")
        
        # è®¡ç®—å‡†ç¡®ç‡
        accuracy_results = self.calculate_accuracy(predictions, ground_truth)
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report = {
            'evaluation_summary': accuracy_results,
            'detailed_predictions': predictions,
            'ground_truth': ground_truth,
            'evaluation_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'total_ips_evaluated': len(predictions)
        }
        
        # ä¿å­˜æŠ¥å‘Š
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # æ‰“å°æ‘˜è¦
        print(f"\n=== è¯„ä¼°æŠ¥å‘Šæ‘˜è¦ ===")
        print(f"æ€»ä½“å‡†ç¡®ç‡: {accuracy_results['overall_accuracy']:.2%}")
        print(f"è¯„ä¼°æ ·æœ¬æ•°: {accuracy_results['total_samples']}")
        print(f"æ­£ç¡®é¢„æµ‹æ•°: {accuracy_results['correct_predictions']}")
        print(f"å¹³å‡ç½®ä¿¡åº¦: {accuracy_results['average_confidence']:.3f}")
        
        print(f"\nå„ç±»å‹å‡†ç¡®ç‡:")
        for anomaly_type, accuracy in accuracy_results['type_accuracies'].items():
            type_name = self.anomaly_type_mapping.get(anomaly_type, anomaly_type)
            print(f"  {type_name}: {accuracy:.2%}")
        
        print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
        
        return report
    
    def run_complete_evaluation(self, anomaly_ips_file, use_graphrag=True):
        """
        è¿è¡Œå®Œæ•´çš„è¯„ä¼°æµç¨‹
        """
        print("=== å¼€å§‹å¼‚å¸¸IPåˆ†ç±»è¯„ä¼° ===\n")
        
        # 1. è¯»å–å¼‚å¸¸IPåˆ—è¡¨å’ŒçœŸå®æ ‡ç­¾
        print("1. è¯»å–å¼‚å¸¸IPåˆ—è¡¨å’ŒçœŸå®æ ‡ç­¾...")
        try:
            df = pd.read_csv(anomaly_ips_file, encoding='utf-8')
            
            # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
            if df.shape[1] < 2:
                print("âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šéœ€è¦è‡³å°‘ä¸¤åˆ—ï¼ˆIPåœ°å€ï¼Œå¼‚å¸¸ç±»å‹ï¼‰")
                print("å½“å‰æ–‡ä»¶åˆ—æ•°:", df.shape[1])
                print("æ–‡ä»¶å†…å®¹é¢„è§ˆ:")
                print(df.head())
                return None
            
            # è¯»å–IPåˆ—è¡¨ï¼ˆç¬¬ä¸€åˆ—ï¼‰
            anomaly_ips = df.iloc[:, 0].dropna().astype(str).unique().tolist()
            print(f"   å‘ç° {len(anomaly_ips)} ä¸ªå¼‚å¸¸IP")
            
            # è¯»å–çœŸå®æ ‡ç­¾ï¼ˆç¬¬äºŒåˆ—ï¼‰
            ground_truth = self.load_ground_truth_from_csv(anomaly_ips_file)
            
            if not ground_truth:
                print("âŒ æ— æ³•åŠ è½½çœŸå®æ ‡ç­¾ï¼Œè¯„ä¼°æ— æ³•è¿›è¡Œ")
                return None
                
        except Exception as e:
            print(f"âŒ è¯»å–å¼‚å¸¸IPæ–‡ä»¶å¤±è´¥: {e}")
            return None
        
        # 2. æ‰§è¡Œåˆ†ç±»é¢„æµ‹
        print(f"\n2. æ‰§è¡Œåˆ†ç±»é¢„æµ‹ï¼ˆä½¿ç”¨{'GraphRAG' if use_graphrag else 'Ollamaç›´æ¥æŸ¥è¯¢'}ï¼‰...")
        predictions = self.classify_batch_ips(anomaly_ips, use_graphrag)
        
        # 3. è®¡ç®—å‡†ç¡®ç‡å’Œç”ŸæˆæŠ¥å‘Š
        print(f"\n3. ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š...")
        report = self.generate_evaluation_report(predictions, ground_truth)
        
        # 4. ä¿å­˜é¢„æµ‹ç»“æœ
        predictions_file = "ip_classification_predictions.json"
        with open(predictions_file, 'w', encoding='utf-8') as f:
            json.dump(predictions, f, ensure_ascii=False, indent=2)
        
        # 5. ä¿å­˜çœŸå®æ ‡ç­¾ï¼ˆä¾¿äºåç»­ä½¿ç”¨ï¼‰
        ground_truth_file = "ground_truth_from_csv.json"
        with open(ground_truth_file, 'w', encoding='utf-8') as f:
            json.dump(ground_truth, f, ensure_ascii=False, indent=2)
        
        print(f"\n=== è¯„ä¼°å®Œæˆ ===")
        print(f"é¢„æµ‹ç»“æœæ–‡ä»¶: {predictions_file}")
        print(f"è¯„ä¼°æŠ¥å‘Šæ–‡ä»¶: evaluation_report.json")
        print(f"çœŸå®æ ‡ç­¾æ–‡ä»¶: {ground_truth_file}")
        
        return {
            'predictions': predictions,
            'ground_truth': ground_truth,
            'evaluation_report': report
        }


def main():
    """
    ä¸»å‡½æ•° - ä½¿ç”¨ç¤ºä¾‹
    """
    # é…ç½®å‚æ•°
    graphrag_workspace = "graphrag_workspace"  # GraphRAGå·¥ä½œç›®å½•
    anomaly_ips_file = "abnormal_ips.csv"      # å¼‚å¸¸IPæ–‡ä»¶
    
    # åˆ›å»ºåˆ†ç±»å™¨
    classifier = AnomalyIPClassifier(graphrag_workspace)
    
    # æ£€æŸ¥GraphRAGå·¥ä½œç›®å½•
    if not Path(graphrag_workspace).exists():
        print(f"âŒ GraphRAGå·¥ä½œç›®å½•ä¸å­˜åœ¨: {graphrag_workspace}")
        print("è¯·å…ˆè¿è¡ŒGraphRAGéƒ¨ç½²å™¨")
        return
    
    # è¿è¡Œå®Œæ•´è¯„ä¼°
    try:
        result = classifier.run_complete_evaluation(
            anomaly_ips_file, 
            use_graphrag=True  # è®¾ç½®ä¸ºFalseå¯ä»¥ç›´æ¥ä½¿ç”¨ollama
        )
        
        if result:
            print("\nğŸ‰ å¼‚å¸¸IPåˆ†ç±»è¯„ä¼°å®Œæˆï¼")
            print("\nå¯ä»¥æŸ¥çœ‹ä»¥ä¸‹æ–‡ä»¶äº†è§£è¯¦ç»†ç»“æœ:")
            print("- ip_classification_predictions.json (é¢„æµ‹ç»“æœ)")
            print("- evaluation_report.json (è¯„ä¼°æŠ¥å‘Š)")
            print("- ground_truth_classifications.json (çœŸå®æ ‡ç­¾)")
        else:
            print("\nâŒ è¯„ä¼°è¿‡ç¨‹å¤±è´¥")
            
    except Exception as e:
        print(f"è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()