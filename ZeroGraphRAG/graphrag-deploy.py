#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GraphRAGéƒ¨ç½²å™¨
é…ç½®å’Œéƒ¨ç½²GraphRAGç³»ç»Ÿï¼Œé›†æˆollamaæœ¬åœ°å¤§æ¨¡å‹

ä½œè€…: WebSWEAgent
æ—¥æœŸ: 2025-08-10
"""

import os
import json
import yaml
import subprocess
import requests
import time
from pathlib import Path

class GraphRAGDeployer:
    def __init__(self, work_dir="graphrag_workspace"):
        """
        åˆå§‹åŒ–GraphRAGéƒ¨ç½²å™¨
        """
        self.work_dir = Path(work_dir)
        self.work_dir.mkdir(exist_ok=True)
        
        # GraphRAGé…ç½®
        self.config = {
            "llm": {
                "api_type": "openai_chat",
                "api_base": "http://localhost:11434/v1",
                "api_key": "ollama",
                "model": "qwen2.5:7b",  # å¯ä»¥æ ¹æ®éœ€è¦æ›´æ”¹æ¨¡å‹
                "max_tokens": 4000,
                "temperature": 0.1
            },
            "embeddings": {
                "api_type": "openai_embedding",
                "api_base": "http://localhost:11434/v1", 
                "api_key": "ollama",
                "model": "nomic-embed-text",
                "max_tokens": 8191
            },
            "input": {
                "type": "file",
                "file_type": "text",
                "base_dir": "./input",
                "file_encoding": "utf-8"
            },
            "cache": {
                "type": "file",
                "base_dir": "./cache"
            },
            "storage": {
                "type": "file",
                "base_dir": "./output"
            },
            "chunk_size": 1200,
            "chunk_overlap": 100,
            "entity_extraction": {
                "strategy": {
                    "type": "graph_intelligence",
                    "llm": {
                        "api_type": "openai_chat",
                        "api_base": "http://localhost:11434/v1",
                        "api_key": "ollama",
                        "model": "qwen2.5:7b"
                    }
                }
            },
            "summarize_descriptions": {
                "strategy": {
                    "type": "graph_intelligence",
                    "llm": {
                        "api_type": "openai_chat", 
                        "api_base": "http://localhost:11434/v1",
                        "api_key": "ollama",
                        "model": "qwen2.5:7b"
                    }
                }
            },
            "community_reports": {
                "strategy": {
                    "type": "graph_intelligence",
                    "llm": {
                        "api_type": "openai_chat",
                        "api_base": "http://localhost:11434/v1", 
                        "api_key": "ollama",
                        "model": "qwen2.5:7b"
                    }
                }
            }
        }
    
    def check_ollama_status(self):
        """
        æ£€æŸ¥ollamaæœåŠ¡çŠ¶æ€
        """
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get('models', [])
                print(f"âœ… OllamaæœåŠ¡è¿è¡Œæ­£å¸¸ï¼Œå·²å®‰è£…æ¨¡å‹: {len(models)}ä¸ª")
                for model in models:
                    print(f"   - {model['name']}")
                return True
            else:
                print("âŒ OllamaæœåŠ¡å“åº”å¼‚å¸¸")
                return False
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡: {e}")
            return False
    
    def install_required_models(self):
        """
        å®‰è£…GraphRAGæ‰€éœ€çš„æ¨¡å‹
        """
        required_models = [
            "qwen2.5:7b",  # ä¸»è¦çš„LLMæ¨¡å‹
            "nomic-embed-text"  # åµŒå…¥æ¨¡å‹
        ]
        
        print("æ£€æŸ¥å¹¶å®‰è£…æ‰€éœ€æ¨¡å‹...")
        
        for model in required_models:
            print(f"æ£€æŸ¥æ¨¡å‹: {model}")
            try:
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å®‰è£…
                response = requests.post(
                    "http://localhost:11434/api/show",
                    json={"name": model},
                    timeout=10
                )
                
                if response.status_code == 200:
                    print(f"âœ… æ¨¡å‹ {model} å·²å®‰è£…")
                else:
                    print(f"â¬‡ï¸ æ­£åœ¨ä¸‹è½½æ¨¡å‹ {model}...")
                    # æ‹‰å–æ¨¡å‹
                    pull_response = requests.post(
                        "http://localhost:11434/api/pull",
                        json={"name": model},
                        timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
                    )
                    
                    if pull_response.status_code == 200:
                        print(f"âœ… æ¨¡å‹ {model} ä¸‹è½½å®Œæˆ")
                    else:
                        print(f"âŒ æ¨¡å‹ {model} ä¸‹è½½å¤±è´¥")
                        return False
                        
            except Exception as e:
                print(f"âŒ å¤„ç†æ¨¡å‹ {model} æ—¶å‡ºé”™: {e}")
                return False
        
        return True
    
    def setup_graphrag_environment(self):
        """
        è®¾ç½®GraphRAGç¯å¢ƒ
        """
        print("è®¾ç½®GraphRAGç¯å¢ƒ...")
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        directories = ['input', 'output', 'cache', 'prompts']
        for dir_name in directories:
            (self.work_dir / dir_name).mkdir(exist_ok=True)
        
        # ç”Ÿæˆé…ç½®æ–‡ä»¶
        config_path = self.work_dir / "settings.yaml"
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(self.config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"âœ… GraphRAGé…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {config_path}")
        
        # ç”Ÿæˆç¯å¢ƒå˜é‡æ–‡ä»¶
        env_path = self.work_dir / ".env"
        with open(env_path, 'w') as f:
            f.write("GRAPHRAG_API_KEY=ollama\n")
            f.write("GRAPHRAG_LLM_TYPE=openai_chat\n")
            f.write("GRAPHRAG_EMBEDDING_TYPE=openai_embedding\n")
        
        print(f"âœ… ç¯å¢ƒå˜é‡æ–‡ä»¶å·²ç”Ÿæˆ: {env_path}")
        
        return True
    
    def copy_knowledge_data(self, knowledge_dir):
        """
        å¤åˆ¶çŸ¥è¯†å›¾è°±æ•°æ®åˆ°GraphRAGè¾“å…¥ç›®å½•
        """
        print("å¤åˆ¶çŸ¥è¯†æ•°æ®åˆ°GraphRAG...")
        
        knowledge_path = Path(knowledge_dir)
        if not knowledge_path.exists():
            print(f"âŒ çŸ¥è¯†æ•°æ®ç›®å½•ä¸å­˜åœ¨: {knowledge_dir}")
            return False
        
        # å¤åˆ¶æ–‡æ¡£æ•°æ®
        input_file = knowledge_path / "input_documents.txt"
        if input_file.exists():
            import shutil
            target_file = self.work_dir / "input" / "dns_knowledge.txt"
            shutil.copy2(input_file, target_file)
            print(f"âœ… çŸ¥è¯†æ–‡æ¡£å·²å¤åˆ¶åˆ°: {target_file}")
        else:
            print(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡æ¡£: {input_file}")
            return False
        
        # å¤åˆ¶åˆ†ç±»æ•°æ®
        classification_file = knowledge_path / "anomaly_classifications.json"
        if classification_file.exists():
            import shutil
            target_file = self.work_dir / "anomaly_classifications.json"
            shutil.copy2(classification_file, target_file)
            print(f"âœ… å¼‚å¸¸åˆ†ç±»æ•°æ®å·²å¤åˆ¶åˆ°: {target_file}")
        
        return True
    
    def initialize_graphrag(self):
        """
        åˆå§‹åŒ–GraphRAGç´¢å¼•
        """
        print("åˆå§‹åŒ–GraphRAGç´¢å¼•...")
        
        try:
            # åˆ‡æ¢åˆ°å·¥ä½œç›®å½•
            original_dir = os.getcwd()
            os.chdir(self.work_dir)
            
            # è¿è¡ŒGraphRAGåˆå§‹åŒ–ï¼ˆWindowsç¼–ç ä¿®å¤ï¼‰
            result = subprocess.run(
                ["python", "-m", "graphrag.index", "--init"],
                capture_output=True,
                text=True,
                encoding='utf-8',
                errors='ignore',
                timeout=300
            )
            
            if result.returncode == 0:
                print("âœ… GraphRAGåˆå§‹åŒ–æˆåŠŸ")
                print("å¼€å§‹æ„å»ºçŸ¥è¯†å›¾è°±ç´¢å¼•...")
                
                # è¿è¡Œç´¢å¼•æ„å»ºï¼ˆWindowsç¼–ç ä¿®å¤ï¼‰
                index_result = subprocess.run(
                    ["python", "-m", "graphrag.index", "--root", "."],
                    capture_output=True,
                    text=True,
                    encoding='utf-8',
                    errors='ignore',
                    timeout=1800  # 30åˆ†é’Ÿè¶…æ—¶
                )
                
                if index_result.returncode == 0:
                    print("âœ… çŸ¥è¯†å›¾è°±ç´¢å¼•æ„å»ºæˆåŠŸ")
                    return True
                else:
                    error_msg = index_result.stderr or "æœªçŸ¥é”™è¯¯"
                    print(f"âŒ ç´¢å¼•æ„å»ºå¤±è´¥: {error_msg}")
                    return False
            else:
                error_msg = result.stderr or "æœªçŸ¥é”™è¯¯"
                print(f"âŒ GraphRAGåˆå§‹åŒ–å¤±è´¥: {error_msg}")
                return False
                
        except subprocess.TimeoutExpired:
            print("âŒ GraphRAGæ“ä½œè¶…æ—¶")
            return False
        except UnicodeDecodeError as e:
            print(f"âŒ ç¼–ç é”™è¯¯: {e}")
            print("å°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•...")
            return self._initialize_graphrag_fallback()
        except Exception as e:
            print(f"âŒ GraphRAGæ“ä½œå‡ºé”™: {e}")
            return False
        finally:
            os.chdir(original_dir)
    
    def _initialize_graphrag_fallback(self):
        """
        GraphRAGåˆå§‹åŒ–çš„å¤‡ç”¨æ–¹æ³•ï¼ˆå¤„ç†Windowsç¼–ç é—®é¢˜ï¼‰
        """
        try:
            original_dir = os.getcwd()
            os.chdir(self.work_dir)
            
            print("ä½¿ç”¨å¤‡ç”¨æ–¹æ³•åˆå§‹åŒ–GraphRAG...")
            
            # ä½¿ç”¨bytesæ¨¡å¼é¿å…ç¼–ç é—®é¢˜
            result = subprocess.run(
                ["python", "-m", "graphrag.index", "--init"],
                capture_output=True,
                timeout=300
            )
            
            if result.returncode == 0:
                print("âœ… GraphRAGåˆå§‹åŒ–æˆåŠŸï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰")
                
                # æ„å»ºç´¢å¼•
                index_result = subprocess.run(
                    ["python", "-m", "graphrag.index", "--root", "."],
                    capture_output=True,
                    timeout=1800
                )
                
                if index_result.returncode == 0:
                    print("âœ… çŸ¥è¯†å›¾è°±ç´¢å¼•æ„å»ºæˆåŠŸï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰")
                    return True
                else:
                    print("âŒ ç´¢å¼•æ„å»ºå¤±è´¥ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰")
                    return False
            else:
                print("âŒ GraphRAGåˆå§‹åŒ–å¤±è´¥ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰")
                return False
                
        except Exception as e:
            print(f"âŒ å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
            return False
        finally:
            os.chdir(original_dir)
    
    def test_graphrag_query(self):
        """
        æµ‹è¯•GraphRAGæŸ¥è¯¢åŠŸèƒ½
        """
        print("æµ‹è¯•GraphRAGæŸ¥è¯¢åŠŸèƒ½...")
        
        test_queries = [
            "ä»€ä¹ˆæ˜¯DNSéš§é“æ”»å‡»ï¼Ÿ",
            "å¦‚ä½•è¯†åˆ«åƒµå°¸ç½‘ç»œC&Cé€šä¿¡ï¼Ÿ",
            "å¼‚å¸¸IPçš„ä¸»è¦ç±»å‹æœ‰å“ªäº›ï¼Ÿ"
        ]
        
        try:
            original_dir = os.getcwd()
            os.chdir(self.work_dir)
            
            for query in test_queries:
                print(f"\næµ‹è¯•æŸ¥è¯¢: {query}")
                
                result = subprocess.run(
                    ["python", "-m", "graphrag.query", 
                     "--root", ".", 
                     "--method", "global",
                     query],
                    capture_output=True,
                    text=True,
                    encoding='utf-8',
                    errors='ignore',
                    timeout=60
                )
                
                if result.returncode == 0:
                    print(f"âœ… æŸ¥è¯¢æˆåŠŸ")
                    output = result.stdout[:200] if result.stdout else "æ— è¾“å‡º"
                    print(f"å›ç­”: {output}...")
                else:
                    error_msg = result.stderr or "æœªçŸ¥é”™è¯¯"
                    print(f"âŒ æŸ¥è¯¢å¤±è´¥: {error_msg}")
            
            return True
            
        except UnicodeDecodeError as e:
            print(f"âŒ ç¼–ç é”™è¯¯: {e}")
            print("GraphRAGæŸ¥è¯¢æµ‹è¯•è·³è¿‡ï¼ˆç¼–ç é—®é¢˜ï¼‰")
            return True  # ä¸å› ä¸ºæµ‹è¯•å¤±è´¥è€Œä¸­æ–­éƒ¨ç½²
        except Exception as e:
            print(f"âŒ æµ‹è¯•æŸ¥è¯¢å‡ºé”™: {e}")
            return False
        finally:
            os.chdir(original_dir)
    
    def deploy_complete_system(self, knowledge_dir):
        """
        éƒ¨ç½²å®Œæ•´çš„GraphRAGç³»ç»Ÿ
        """
        print("=== å¼€å§‹éƒ¨ç½²GraphRAGç³»ç»Ÿ ===\n")
        
        # 1. æ£€æŸ¥ollamaæœåŠ¡
        if not self.check_ollama_status():
            print("è¯·å…ˆå¯åŠ¨ollamaæœåŠ¡: ollama serve")
            return False
        
        # 2. å®‰è£…æ‰€éœ€æ¨¡å‹
        if not self.install_required_models():
            print("æ¨¡å‹å®‰è£…å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            return False
        
        # 3. è®¾ç½®GraphRAGç¯å¢ƒ
        if not self.setup_graphrag_environment():
            print("GraphRAGç¯å¢ƒè®¾ç½®å¤±è´¥")
            return False
        
        # 4. å¤åˆ¶çŸ¥è¯†æ•°æ®
        if not self.copy_knowledge_data(knowledge_dir):
            print("çŸ¥è¯†æ•°æ®å¤åˆ¶å¤±è´¥")
            return False
        
        # 5. åˆå§‹åŒ–GraphRAG
        if not self.initialize_graphrag():
            print("GraphRAGåˆå§‹åŒ–å¤±è´¥")
            return False
        
        # 6. æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½
        if not self.test_graphrag_query():
            print("æŸ¥è¯¢åŠŸèƒ½æµ‹è¯•å¤±è´¥")
            return False
        
        print("\n=== GraphRAGç³»ç»Ÿéƒ¨ç½²å®Œæˆ ===")
        print(f"å·¥ä½œç›®å½•: {self.work_dir}")
        print("å¯ä»¥å¼€å§‹ä½¿ç”¨GraphRAGè¿›è¡Œå¼‚å¸¸IPåˆ†ç±»æŸ¥è¯¢")
        
        return True


def main():
    """
    ä¸»å‡½æ•° - éƒ¨ç½²ç¤ºä¾‹
    """
    # é…ç½®å‚æ•°
    knowledge_dir = "graphrag_knowledge"  # çŸ¥è¯†å›¾è°±æ•°æ®ç›®å½•
    work_dir = "graphrag_workspace"       # GraphRAGå·¥ä½œç›®å½•
    
    # åˆ›å»ºéƒ¨ç½²å™¨
    deployer = GraphRAGDeployer(work_dir)
    
    # éƒ¨ç½²ç³»ç»Ÿ
    success = deployer.deploy_complete_system(knowledge_dir)
    
    if success:
        print("\nğŸ‰ GraphRAGç³»ç»Ÿéƒ¨ç½²æˆåŠŸï¼")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print(f"1. cd {work_dir}")
        print("2. python -m graphrag.query --root . --method global 'æŸ¥è¯¢å†…å®¹'")
        print("3. æˆ–è€…ä½¿ç”¨æä¾›çš„Python APIè¿›è¡ŒæŸ¥è¯¢")
    else:
        print("\nâŒ GraphRAGç³»ç»Ÿéƒ¨ç½²å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")


if __name__ == "__main__":
    main()